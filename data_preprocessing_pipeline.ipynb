{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c1179fc-0c7a-4c00-83da-4d9d70c21cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/the-verdict.txt\", 'r') as f:\n",
    "    raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d397d8f-59f1-483b-8d7f-1cd73d0925e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20479"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc543fa-3758-4597-adfb-600c5eea8e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92a1eda-b36b-4bca-aa2e-cd4d84d2e86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello,', ' ', 'kid.', ' ', 'How', ' ', 'are', ' ', 'you', ' ', 'doing?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt = \"Hello, kid. How are you doing?\"\n",
    "res = re.split(r\"(\\s)\", txt)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0439794d-d8c5-45d3-a7c8-4a2b872803e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'kid', '.', 'How', 'are', 'you', 'doing', '?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = re.split(r'([,.!:;?_\"()\\']|--|\\s)', txt)\n",
    "res = [item.strip() for item in res if item.strip()]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706e8a42-ff41-4fe8-ab63-311eff4e8f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'HAD',\n",
       " 'always',\n",
       " 'thought',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'cheap',\n",
       " 'genius',\n",
       " '--',\n",
       " 'though',\n",
       " 'a',\n",
       " 'good',\n",
       " 'fellow']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.!:;?_\"()\\']|--|\\s)', raw)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "preprocessed[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596ef425-1d93-4308-b4bb-5ff253bcfeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b7d75db-9ac7-424b-9ffb-edc74d301aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token id assignment\n",
    "total_words = sorted(set(preprocessed))\n",
    "vocab_size = len(total_words)\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed3d3875-73d5-4294-9018-6eed167edf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer, token in enumerate(total_words)}\n",
    "\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99aa8d27-ceab-421d-bdc9-1c71ed329b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer class - encode and decode\n",
    "\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.!:;?_\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'([,.!:;?_\"()\\']|--|\\s)', r'\\1', text)\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e988ac9f-924f-4882-bd0c-6b9bc1a7a05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"It's the last he painted, you know!\"\n",
    "ids = tokenizer.encode(text)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a264be8-695b-4101-a62b-0b7a0e162dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It ' s the last he painted , you know !\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d4708a5-df18-41d6-b879-8a28009b8473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[560, 169, 1126, 10]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"how are you?\"\n",
    "tokenizer.encode(text)\n",
    "# out of vocabulary keywords like \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0310826e-0297-4989-a3f3-570adcbe7f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = sorted(list(set(preprocessed)))\n",
    "total_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer, token in enumerate(total_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9dd7818-1357-49d7-aff8-4a9ec9692a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a034753e-f592-45ba-ab18-b3914772d7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2b4498f-0042-46d1-952f-8ef63626f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer updated class - encode and decode\n",
    "\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i: s for s, i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.!:;?_\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int\n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'([,.!:;?_\"()\\']|--|\\s)', r'\\1', text)\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "496e951c-b859-47de-9af3-d3f5f7ac8cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello bro what's up! <|endoftext|> Sunlight is mesmerising.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello bro what's up!\"\n",
    "text2 = \"Sunlight is mesmerising.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e614607-9834-4016-baba-4c5b9309327f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 1131, 1089, 2, 850, 1051, 0, 1130, 1131, 584, 1131, 7]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79276319-c4ee-4d14-8d65-b0235f4e14cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|unk|> <|unk|> what ' s up ! <|endoftext|> <|unk|> is <|unk|> .\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1693e2ba-c76f-49ff-98ce-e7a543f631ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPE\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d786071-1e1e-4278-95bd-bfec9b812e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496,\n",
       " 1379,\n",
       " 644,\n",
       " 338,\n",
       " 510,\n",
       " 0,\n",
       " 220,\n",
       " 50256,\n",
       " 3825,\n",
       " 2971,\n",
       " 1042,\n",
       " 274,\n",
       " 647,\n",
       " 1710,\n",
       " 13]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello bro what's up! <|endoftext|> Sunlightismesmerising.\"\n",
    "\n",
    "ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "986b5c49-4341-45b4-bb70-f3f80c5afe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello bro what's up! <|endoftext|> Sunlightismesmerising.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db8d87a5-e479-4ace-b378-d2fb2d8143de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap g'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating input-target pairs\n",
    "\n",
    "raw[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2230997-1c4c-457d-85c2-4802b4da49ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5145"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw)\n",
    "len(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "842fe4b1-1505-408c-aaca-fce8fb731566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 367, 2885, 1464, 1807]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = enc_text[:50]\n",
    "sample[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4296d8cf-b041-4d28-909e-98e9d2f15b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4\n",
    "\n",
    "x = sample[:context_size]\n",
    "y = sample[1:context_size + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ebdb785-60e8-4ed7-9ab5-58998d186392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [40, 367, 2885, 1464]\n",
      "Y:     [367, 2885, 1464, 1807]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X: {x}\")\n",
    "print(f\"Y:     {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6010da7d-e4cb-4d27-b9a6-dbce799946d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] --> 367\n",
      "[40, 367] --> 2885\n",
      "[40, 367, 2885] --> 1464\n",
      "[40, 367, 2885, 1464] --> 1807\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    ip = sample[:i]\n",
    "    t = sample[i]\n",
    "    print(f\"{ip} --> {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e0802-fa66-4e24-abb3-4a077f019708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_len, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_len, stride):\n",
    "            ip_chunk = token_ids[i : i + max_len]\n",
    "            target_chunk = token_ids[i + 1 : i + max_len + 1]\n",
    "            self.input_ids.append(torch.tensor(ip_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
